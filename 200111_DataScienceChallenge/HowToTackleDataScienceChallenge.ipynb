{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMMARY\n",
    "**0) Preliminary works**\n",
    "> 0.1) Prepare sample file <br>\n",
    "> 0.2) read_csv with nrows option<br>\n",
    "\n",
    "**1) Get familiar with data**<br>\n",
    "**2) Select columns of interest**<br>\n",
    "**3) What to do with NaN**<br>\n",
    "**4) Make an action plan**<br>\n",
    "**5) Adjust the code to work with Big data**<br>\n",
    "> 5.1) Create an ITERATOR from the data base and define CHUNK size <br>\n",
    "> 5.2) Test Big Data approach on a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERAL SETTINGS\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None) #so we can see all the file columns\n",
    "\n",
    "#or\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Preliminary works\n",
    "\n",
    "If we don´t want to read the whole file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1) Prepare sample file\n",
    "with command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAKING FIRST 10000 ROWS AND CREATING A SAMPLE FILE\n",
    "!bzcat bookings.csv.bz2 | head -10000 > bookings.sample.csv\n",
    "#READ FILE WITH PANDAS\n",
    "b = pd.read_csv('bookings.sample.csv.bz2', sep='^')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAKING FIRST 10000 ROWS\n",
    "b = pd.read_csv('bookings.csv.bz2', sep='^', nrows=9999)\n",
    "\n",
    "#TAKING RANDOM SAMPLE OF 10000 ROWS\n",
    "import random\n",
    "\n",
    "p = 0.01\n",
    "b_muestra = pd.read_csv('bookings.csv.bz2',sep='^',header=0,\n",
    "                        skiprows=lambda i: i>0 and random.random() > p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2) read_csv with nrows option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAKE JUST 10000 LINES\n",
    "b = pd.read_csv('bookings.csv.bz2', sep='^', nrows=9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Get familiar with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE THE FOLLOWING FUNCTIONS\n",
    "b.shape         #check nº of rows and columns\n",
    "list(b.columns) #check white spaces in column names\n",
    "b.sample()      #check random sample\n",
    "                #ask for the data dictionary and study all fields\n",
    "b.info()        #check data types and spot nulls\n",
    "b.describe()    #check descriptive statistics\n",
    "\n",
    "#Analyze date with:\n",
    "groupby()\n",
    "count()\n",
    "sum()\n",
    "sort_values()\n",
    "head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Select columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_csv('bookings.csv.bz2', sep='^', usecols=['arr_port', 'pax', 'year'], nrows=9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) What to do with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decide whether to eliminate columns/rows with NaNs\n",
    "#or replace NaNs with other values\n",
    "b = b.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Make an action plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elaborate a list of actions to process your code.\n",
    "One action can be equal to one command to execute.\n",
    "\n",
    "EXAMPLE:\n",
    "\n",
    "1) filter 2013 rows\n",
    "2) groupby arr_port\n",
    "3) sum pax\n",
    "4) sort by pax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the code, put it together in a single cell so you can execute it at once without worrings in which cells that or that variable was created, etc...\n",
    "Example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "b = pd.read_csv('bookings.csv.bz2',sep='^', usecols=['arr_port', 'pax', 'year'], nrows=9999)\n",
    "b = b.dropna()\n",
    "b=b[ b['year']==2013 ]\n",
    "del b['year']\n",
    "b.groupby(['arr_port']).sum().sort_values('pax', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Adjust the code to work with Big data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we now that our code works with the sample file, we need to run it in chunks over the original data base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1) Create an ITERATOR from the data base and define CHUNK size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our machine does not normally has enough memory to read an entire big CSV into a DataFrame. The solution is to process the CSV in CHUNKS.\n",
    "\n",
    "To read a file in chunks we need an ITERATOR OBJECT.\n",
    "When you read a file in chunks, the cursor moves through the rows. If the last chunks exceeds the last row, you will get an error.\n",
    "\n",
    "An ITERATOR OBJECT has the property of stopping the reading process without causing an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code returns an iterator instead of a DataFrame\n",
    "bi = pd.read_csv('bookings.csv.bz2', sep='^', usecols=['arr_port', 'pax', 'year'], nrows=9999, iterator=True)\n",
    "\n",
    "#this code returns a chunk of the file\n",
    "bi.get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define CHUNK SIZE with read_csv also returns and ITERATOR with a predefined chunk size\n",
    "bi = pd.read_csv('bookings.csv.bz2', sep='^', usecols=['arr_port', 'pax', 'year'], nrows=9999, chunksize=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) Test Big Data approach on a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Big Data approach is to run the code by file chunks and append the results at the end.\n",
    "\n",
    "We have to test this approach in smaller chunks, taken from the sample of 10000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RECAP 1\n",
    "#this is the code we were running on the above sample\n",
    "b = b.dropna()\n",
    "b=b[ b['year']==2013 ]\n",
    "del b['year']\n",
    "b.groupby(['arr_port']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RECAP 2\n",
    "#set options\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#get 10000 rows sample iterator with 3000 chunks\n",
    "bi = pd.read_csv('bookings.csv.bz2', sep='^', usecols=['arr_port', 'pax', 'year'], nrows=9999, chunksize=3000)\n",
    "\n",
    "#declare empty DataFrame to store results of each chunk\n",
    "all_chunks=pd.DataFrame()\n",
    "\n",
    "#iterate through chunks and append results\n",
    "for i, b in enumerate(bi):\n",
    "    print(i, len(b))    \n",
    "    b=b.dropna()\n",
    "    b=b[b['year']==2013]\n",
    "    del b['year']\n",
    "    result=b.groupby(['arr_port']).sum()\n",
    "    \n",
    "    all_chunks=all_chunks.append(result)\n",
    "\n",
    "#groupby puts the grouping column as index so we have to:\n",
    "#reset_index()\n",
    "#groupby again the all_chunks results > sum > sort > reset_index again\n",
    "result_all = all_chunks.reset_index().groupby(['arr_port']).sum().sort_values(by='pax', ascending=False).reset_index()\n",
    "result_all.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the result_all is the same as the one executed for a single sample (without chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Run program with Big Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meaning, don´t take just 9999 rows but all (removing 'nrows=9999')\n",
    "bi = pd.read_csv('bookings.csv.bz2', sep='^', usecols=['arr_port', 'pax', 'year'], chunksize=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get familiar with data\n",
    "Select the columns of interest\n",
    "What to do with Na?\n",
    "\n",
    "Make action plan\n",
    "Develop the code that works with a sample\n",
    "\n",
    "5 Adjust the code to work with Big data\n",
    "Test big data approach on a sample\n",
    "\n",
    "6 Run program with big data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
